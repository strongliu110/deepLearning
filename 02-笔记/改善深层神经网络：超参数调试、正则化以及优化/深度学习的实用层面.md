# 深度学习的实用层面

## 1.1 训练/开发/测试集

选择最佳的训练集（Training sets）、验证集（Development sets）、测试集（Test sets）对神经网络的性能影响非常重要。

通常来说，最适合某个领域的深度学习网络往往不能直接应用在其它问题上。应用深度学习是一个反复迭代的过程，需要通过反复多次的循环训练得到最优化参数。决定整个训练过程快慢的关键在于单次循环所花费的时间，单次循环越快，训练过程越快。而设置合适的Train/Dev/Test sets数量，能有效提高训练效率。

一般地，我们将所有的样本数据分成三个部分：Train/Dev/Test sets。Train sets用来训练你的算法模型；Dev sets用来验证不同算法的表现情况，从中选择最好的算法模型；Test sets用来测试最好算法的实际表现，作为该算法的无偏估计。

传统机器学习由于数据量比较小, 通常将数据分成 7:3 这样的 train/test 集，或 6:2:2 这样的 train/dev/test 集; 但深度学习由于用到大量的数据，不必为 dev 或 test 分配太多的数据，应将绝大多数数据用于 train，因此一般性的数据划分可以是 98:1:1 或 99.5:0.4:0.1 这样的。

**Train set 与 dev/test 的数据可能来自不同的分布，但要尽量保证 dev 与 test 的数据具有相同的分布**。

训练样本非常重要，通常我们可以将现有的训练样本做一些处理，例如图片的翻转、假如随机噪声等，来扩大训练样本的数量，从而让该模型更加强大。即使Train sets和Dev/Test sets不来自同一分布，使用这些技巧也能提高模型性能。

设立 dev 的目的是，从训练得到的多个模型中找到最优的模型，而 test 的目的是检验选择的模型的泛化能力。因此可以不要 test set。上述的 train/test, 更确切的说法应为 train/dev。

## 1.2 偏差/方差

偏差（Bias）和方差（Variance）是机器学习领域非常重要的两个概念和需要解决的问题。在传统的机器学习算法中，Bias和Variance是对立的，分别对应着欠拟合和过拟合，我们常常需要在Bias和Variance之间进行权衡。而在深度学习中，我们可以同时减小Bias和Variance，构建最佳神经网络模型。

**高偏差对应欠拟合(underfit)，高方差对应过拟合(overfit)。**

对于输入特征是高维的情况，我们可以通过两个数值Train set error和Dev set error来理解bias和variance。一般来说，**Train set error体现了是否出现bias，Dev set error体现了是否出现variance**。正确地说，应该是Dev set error与Train set error的相对差值（base error不同）。

训练误差远高于人类水平 human level, 意味着高偏差, 欠拟合; 检验误差与训练误差很大, 意味着高方差, 过拟合。对于某项任务, 人类误差也很大的情况下, 训练误差很大, 但接近人类水平, 不称为欠拟合。 训练误差与人类水平 (误差)之间的差距, 称为**可避免偏差 avoidable bias**。

## 1.3 机器学习基础

机器学习中基本的一个诀窍就是避免出现high bias和high variance。

1. 首先，**减少high bias的方法通常是增加神经网络的隐藏层个数、神经元个数，训练时间延长，选择其它更复杂的NN模型等**。在base error不高的情况下，一般都能通过这些方式有效降低和避免high bias，至少在训练集上表现良好。

2. 其次，**减少high variance的方法通常是增加训练样本数据，进行正则化Regularization，选择其他更复杂的NN模型等**。

这里有几点需要注意的：

第一，解决high bias和high variance的方法是不同的。实际应用中通过Train set error和Dev set error判断是否出现了high bias或者high variance，然后再选择针对性的方法解决问题。

第二，传统机器学习算法中，Bias和Variance通常是对立的，减小Bias会增加Variance，减小Variance会增加Bias，这称为**偏差-方差平衡**（trade-off）。**在现在的深度学习中，通过使用更复杂的神经网络和海量的训练样本，一般能够同时有效减小Bias和Variance**。这也是深度学习之所以如此强大的原因之一。

## 1.4 正则化

如果出现了过拟合，即high variance，则需要采用正则化（regularization）来解决。虽然扩大训练样本数量也是减小high variance的一种方法，但是通常获得更多训练样本的成本太高，比较困难。

采用L2 regularization，其表达式为：

$J\left( w,b \right)=\frac{1}{m}\sum_{i=1}^{m}{L\left( \hat{y}^{\left( i \right)},y^{\left( i \right)} \right)+\frac{\lambda }{2m}\left| \left| w \right| \right|_{2}^{2}}$

$\left| \left| w \right| \right|_{2}^{2}=\sum_{j=1}^{n_{x}}{w_{j}^{2}=w^{T}\cdot w}$

为什么只对w进行正则化而不对b进行正则化呢？其实也可以对b进行正则化。但是一般w的维度很大，而b只是一个常数。相比较来说，参数很大程度上由w决定，改变b值对整体模型影响较小。所以，一般为了简便，就忽略对b的正则化了。

采用L1 regularization，其表达式为：

$J\left( w,b \right)=\frac{1}{m}\sum_{i=1}^{m}{L\left( \hat{y}^{\left( i \right)},y^{\left( i \right)} \right)+\frac{\lambda }{2m}\left| \left| w \right| \right|_{1}}$

$\left| \left| w \right| \right|_{1}=\sum_{j=1}^{n_{x}}{\left| w_{j} \right|}$

与L2 regularization相比，L1 regularization得到的w更加稀疏，即很多w为零值（可用于特征选择）。其优点是节约存储空间，因为大部分w为0。然而，实际上L1 regularization在解决high variance方面比L2 regularization并不更具优势。而且，L1的在微分求导方面比较复杂。所以，**一般L2 regularization更加常用**。

L1、L2 regularization中的λ就是正则化参数（超参数的一种）。可以设置λ为不同的值，在Dev set中进行验证，选择最佳的λ。在python中，由于lambda是保留字，所以为了避免冲突，我们使用lambd来表示λ。

在深度学习模型中，L2 regularization的表达式为：

$J\left( w^{\left[ 1 \right]},b^{\left[ 1 \right]},\dotsc,w^{\left[ L \right]},b^{\left[ L \right]} \right)=\frac{1}{m}\sum_{i=1}^{m}{L\left( \hat{y}^{\left( i \right)},y^{\left( i \right)} \right)+\frac{\lambda }{2m}\sum_{l=1}^{L}{\left| \left| w^{\left[ l \right]} \right| \right|^{2}}}$

$\left| \left| w^{\left[ l \right]} \right| \right|^{2}=\sum_{i=1}^{n^{\left[ l \right]}}{\sum_{j=1}^{n^{\left[ l-1 \right]}}{\left( w_{ij}^{\left[ l \right]} \right)^{2}}}$

通常，我们把$\left| \left| w^{\left[ l \right]} \right| \right|^{2}$称为Frobenius范数，记为$\left| \left| w^{\left[ l \right]} \right| \right|_{F}^{2}$。一个矩阵的Frobenius范数就是计算所有元素平方和再开方，如下所示：

$\left| \left| A \right| \right|_{F}=\sqrt{\sum_{i=1}^{m}{\sum_{j=1}^{n}{\left| a_{ij} \right|^{2}}}}$

值得注意的是，由于加入了正则化项，梯度下降算法中的$dw^{\left[ l \right]}$计算表达式需要做如下修改：

$dw^{\left[ l \right]}=dw_{before}^{\left[ l \right]}+\frac{\lambda }{m}w^{\left[ l \right]}$

$w^{\left[ l \right]}:=w^{\left[ l \right]}-\alpha \cdot dw^{\left[ l \right]}$

L2 regularization也被称做**权值衰减**（weight decay）。这是因为，由于加上了正则项，$dw^{\left[ l \right]}$有个增量，在更新$w^{\left[ l \right]}$的时候，会多减去这个增量，使得$w^{\left[ l \right]}$比没有正则项的值要小一些。不断迭代更新，不断地减小。权值更新如下所示，其中$1-\frac{\alpha \lambda }{m}<1$。

![weights_decay.png](http://kissg.me/img/2017-08-22-andrew_ng_dl_course2_note/weights_decay.png)

## 1.5 为什么正则化可以减少过拟合

- 一个理解角度是: 添加了正则项之后, 模型将更偏好于较小的权值。如果使用L2 regularization，当λ很大时，$w^{\left[ l \right]} \approx 0$，这意味着该神经网络模型中的某些神经元实际的作用很小，可以忽略。这相当于闭掉了一些神经元，由参数确定的分割超平面更平滑。这样原本过于复杂的神经网络模型就变得不那么复杂了，模型更简单了。如下图所示，整个简化的神经网络模型变成了一个逻辑回归模型。问题就从high variance变成了high bias了。

![regularization_prevent_overfitting.png](http://kissg.me/img/2017-08-22-andrew_ng_dl_course2_note/regularization_prevent_overfitting.png)

- 另一个理解角度是: 以 tanh 激活函数为例, 随着正则化系数 λ 增大, 权值减小, 则$z^{\left[ l \right]}=W^{\left[ l \right]}a^{\left[ l-1 \right]}+b^{\left[ l \right]}$也减小 (暂时忽略 b)。则此时的$z^{\left[ l \right]}$分布在tanh函数的近似线性区域。那么这个神经元起的作用就相当于是linear regression。如果每个神经元对应的权重w[l]都比较小，那么整个神经网络模型相当于是多个linear regression的组合，即可看成一个linear network。 由此, 正则化后的分割超平面也就更平滑了, 防止了过拟合。

![regularization_prevent_overfitting_2.png](http://kissg.me/img/2017-08-22-andrew_ng_dl_course2_note/regularization_prevent_overfitting_2.png)

## 1.6 Dropout 正则化

Dropout是指在深度学习网络的训练过程中，对于每层的神经元，按照一定的概率将其暂时从网络中丢弃。也就是说，每次训练时，每一层都有部分神经元不工作，起到简化复杂网络模型的效果，从而避免发生过拟合。

一种最常用的 Dropout regularization 是 **Inverted Dropout**。

假设对于第l层神经元，设定保留神经元比例概率keep_prob=0.8，即该层有20%的神经元停止工作。dl为dropout向量，设置dl为随机vector，其中80%的元素为1，20%的元素为0。在python中可以使用如下语句生成dropout vector：

```python
dl = np.random.rand(al.shape[0],al.shape[1])<keep_prob1
```

然后，第l层经过dropout，随机删减20%的神经元，只保留80%的神经元，其输出为：

```python
al = np.multiply(al,dl)
```

最后，还要对al进行scale up处理，即：

```python
al /= keep_prob1
```

之所以要对al进行scale up是为了保证在经过dropout后，al作为下一层神经元的输入值尽量保持不变。假设第l层有50个神经元，经过dropout后，有10个神经元停止工作，这样只有40神经元有作用。那么得到的al只相当于原来的80%。**scale up后，能够尽可能保持al的期望值相比之前没有大的变化**。

Inverted dropout的另外一个好处就是在对该dropout后的神经网络进行测试时能够减少scaling问题。因为在训练时，使用scale up保证al的期望值没有大的变化，测试时就不需要再对样本数据进行类似的尺度伸缩操作了。

对于m个样本，单次迭代训练时，随机删除掉隐藏层一定数量的神经元；然后，在删除后的剩下的神经元上正向和反向更新权重w和常数项b；接着，下一次迭代中，再恢复之前删除的神经元，重新随机删除一定数量的神经元，进行正向和反向更新w和b。不断重复上述过程，直至迭代训练完成。

使用dropout训练结束后，**在测试和实际应用模型时，不需要进行dropout和随机删减神经元**，所有的神经元都在工作。

## 1.7 理解 Dropout

1. Dropout通过每次迭代训练时，随机选择不同的神经元，相当于每次都在不同的神经网络上进行训练，**类似机器学习中Bagging的方法**（三个臭皮匠，赛过诸葛亮），能够防止过拟合
2. 除此之外，**还可以从权重w的角度来解释为什么dropout能够有效防止过拟合**。对于某个神经元来说，某次训练时，它的某些输入在dropout的作用被过滤了。而在下一次训练时，又有不同的某些输入被过滤。经过多次训练后，某些输入被过滤，某些输入被保留。这样，该神经元就不会受某个输入非常大的影响，影响被均匀化了。也就是说，对应的权重w不会很大。这从效果上来说，与L2 regularization是类似的，都是对权重w进行“惩罚”，减小了w的值。

总结一下，**对于同一组训练数据，利用不同的神经网络训练之后，求其输出的平均值可以减少overfitting**。Dropout就是利用这个原理，每次丢掉一定数量的隐藏层神经元，相当于在不同的神经网络上进行训练，这样就减少了神经元之间的依赖性，即每个神经元不能依赖于某几个其他的神经元（指层与层之间相连接的神经元），使神经网络更加能学习到与其他神经元之间的更加健壮（robust）的特征。

不同隐藏层的dropout系数keep_prob可以不同。**越容易出现overfitting的隐藏层，其keep_prob就设置的相对小一些**。实际应用中，不建议对输入层进行dropout。

**Dropout 正则化的一个缺点是，很难去定义成本函数 J**，因为每次都随机关停了一些节点。对此可以通过绘制cost function来进行debug，看看dropout是否正确执行。一般做法是，将所有层的keep_prob全设置为1，再绘制cost function，即涵盖所有神经元，看J是否单调下降。 确保无误之后,，再将keep_prob设置为其它值进行Dropout 正则化。

## 1.8 其他正则化方法

- **数据增强 Data augmentation**是一种在需要更多训练数据时，可以采取的技术手段。它对现有的一份样本，进行一定程度的变换，得到新的样本。

  例如图片识别问题中，可以对已有的图片进行水平翻转、垂直翻转、任意角度旋转、缩放或扩大等等。

  在数字识别中，也可以将原有的数字图片进行任意旋转或者扭曲，或者增加一些noise。

- **早停 early stopping** 也是一种防止过拟合的技术手段. 训练开始时, 训练误差和检验误差都随着迭代的进行而下降, 训练误差理论上会持续下降, 而检验误差在达到某一最小值之后, 随着迭代的继续, 反而会上升. 此时, 应在检验误差达到最小值的时候提前结束迭代, 这就是 early stopping。

  ![early_stopping.png](http://kissg.me/img/2017-08-22-andrew_ng_dl_course2_note/early_stopping.png)

  Early stopping缺点：通常来说，机器学习训练模型有两个目标：一是优化cost function，尽量减小J；二是防止过拟合。这两个目标彼此对立的，即减小J的同时可能会造成过拟合，反之亦然。我们把这二者之间的关系称为正交化（orthogonalization）。在深度学习中，我们可以同时减小Bias和Variance，构建最佳神经网络模型。但是，Early stopping的做法通过减少得带训练次数来防止过拟合，这样J就不会足够小。也就是说，**early stopping将上述两个目标融合在一起，同时优化，但可能没有“分而治之”的效果好**。

  与early stopping相比，L2 regularization可以实现“分而治之”的效果：迭代训练足够多，减小J，而且也能有效防止过拟合。而**L2 regularization的缺点之一是最优的正则化参数λ的选择比较复杂**。对这一点来说，early stopping比较简单。总的来说，L2 regularization更加常用一些。

## 1.9 标准化输入

在训练神经网络时，标准化输入可以提高训练的速度。**标准化（normalizing）输入**就是对训练数据集进行归一化的操作，即将原始数据减去其均值$\mu$后，再除以其方差$\sigma ^{2}$：

零均值化：$\mu =\frac{1}{m}\sum_{i=1}^{m}{X^{\left( i \right)}}$

归一化方差：$\sigma ^{2}=\frac{1}{m}\sum_{i=1}^{m}{\left( X^{\left( i \right)} \right)^{2}}$

标准化输入：$X:=\frac{X-\mu }{\sigma ^{2}}$

以二维平面为例，下图展示了其归一化过程：

![归一化](http://img.blog.csdn.net/20171021154503181?)

值得注意的是，**由于训练集进行了标准化处理，那么对于测试集或在实际应用时，应该使用同样的$\mu$和$\sigma ^{2}$对其进行标准化处理**。这样保证了训练集合测试集的标准化操作一致。

之所以要对输入进行标准化操作，主要是为了让所有输入归一化同样的尺度上，方便进行梯度下降算法时能够更快更准确地找到全局最优解。假如输入特征是二维的，且x1的范围是[1,1000]，x2的范围是[0,1]。如果不进行标准化处理，x1与x2之间分布极不平衡，训练得到的w1和w2也会在数量级上差别很大。这样导致的结果是cost function与w和b的关系可能是一个非常细长的椭圆形碗。对其进行梯度下降算法时，由于w1和w2数值差异很大，只能选择很小的学习因子α，来避免J发生振荡。一旦α较大，必然发生振荡，J不再单调下降。如下左图所示。

然而，如果进行了标准化操作，x1与x2分布均匀，w1和w2数值差别不大，得到的cost function与w和b的关系是类似圆形碗。对其进行梯度下降算法时，α可以选择相对大一些，且J一般不会发生振荡，保证了J是单调下降的。

**标准化输入带来的一个好处是, 使梯度下降算法更快收敛。**

如下右图所示。

![标准化](http://img.blog.csdn.net/20171021161550926?)

另外一种情况，如果输入特征之间的范围本来就比较接近，那么不进行标准化操作也是没有太大影响的。但是，标准化处理在大多数场合下还是值得推荐的。

## 1.10 梯度消失与梯度爆炸

**梯度爆炸/消失（vanishing/exploding gradients）**: 对于一个非常深的深度神经网络，当每一层的权值都略大于 1 或单位矩阵，前向传播到最后，激活函数值将爆炸 (因为指数级增长)； 当每一层的权值都略小与 1 或单位矩阵时，前向传播到最后，激活函数值将无限小 (指数级衰减)。L非常大时，梯度会非常大或非常小，从而引起每次更新的步进长度过大或者过小，这让训练过程十分困难。

举个例子来说明，假设一个多层的每层只包含两个神经元的深度神经网络模型，如下图所示：

![深度神经网络](http://img.blog.csdn.net/20171021170831470?)

为了简化复杂度，便于分析，我们令各层的激活函数为线性函数，即$g\left( Z \right)=Z$。且忽略各层常数项b的影响，令b全部为零。那么，该网络的预测输出$\hat{y}$为：

$\hat{Y}=W^{\left[ L \right]}W^{\left[ L-1 \right]}W^{\left[ L-2 \right]} \dotsm W^{\left[ 3 \right]}W^{\left[ 2 \right]}W^{\left[ 1 \right]}$

如果各层权重$W^{\left[ l \right]}$的元素都稍大于1，例如1.5，则预测输出$\hat{y}$将正比于1.5L。L越大，$\hat{y}$越大，且呈指数型增长，我们称之为数值爆炸。相反，如果各层权重$W^{\left[ l \right]}$的元素都稍小于1，例如0.5，则预测输出$\hat{y}$将正比于0.5L。网络层数L越多，$\hat{y}$呈指数型减小，我们称之为数值消失。

## 1.11 神经网络的权重初始化

**如何改善梯度爆炸/消失这类问题，方法是对权重w进行一些初始化处理**。

深度神经网络模型中，以单个神经元为例，该层(l)的输入个数为n，其输出为：

$z=w_{1}x_{1}+w_{2}x_{2}+ \dotsb+w_{n}x_{n}$ 

$a=g\left( z \right)$

![神经网络](http://img.blog.csdn.net/20171021204641118?)

这里忽略了常数项b。**为了让z不会过大或者过小，思路是让w与n有关，且n越大，w应该越小才好，这样能够保证z不会过大**。一种方法是在初始化权值w时，令其方差等于一个较小的值，如$\frac{1}{n}$。

如果激活函数是tanh，权重w的初始化一般令其方差为$\frac{1}{n}$：

```python
w[l] = np.random.randn(n[l],n[l-1])*np.sqrt(1/n[l-1]) 
```

如果激活函数是ReLU，权重w的初始化一般令其方差为$\frac{2}{n}$：

```python
w[l] = np.random.randn(n[l],n[l-1])*np.sqrt(2/n[l-1])
```

Yoshua Bengio提出了另外一种初始化w的方法，令其方差为$\frac{2}{n^{\left[ l-1 \right]}n^{\left[ l \right]}}$：

```python
w[l] = np.random.randn(n[l],n[l-1])*np.sqrt(2/n[l-1]*n[l]) 
```

## 1.12 梯度的数值逼近

反向传播（Back Propagation）神经网络有一项重要的测试是**梯度检查（gradient checking）**，目的是检查验证反向传播过程中梯度下降算法是否正确。

通常的做法是, 利用极限原理, 设$g\left( \theta  \right)$是$f\left( \theta  \right)$的导数，**则梯度检查就是验证单边误差（one-sided difference）：$\frac{f\left( \theta +\epsilon  \right)-f\left( \theta  \right)}{\epsilon }$近似$g\left( \theta  \right)$，它的逼近误差为$\omicron \left( \epsilon  \right)$。用双边误差（two side difference）：$\frac{f\left( \theta +\epsilon  \right)-f\left( \theta -\epsilon  \right)}{2\epsilon }$，它的逼近误差为$\omicron \left( \epsilon ^{2} \right)$，能获得更高的精度函数。**

![近似梯度值](http://img.blog.csdn.net/20171021214350472?)

利用微分思想，f在点θ处的梯度可以表示成：

$g\left( \theta  \right)=\frac{f\left( \theta +\epsilon  \right)-f\left( \theta -\epsilon  \right)}{2\epsilon }$

其中，$\epsilon >0$，且足够小。

## 1.13 梯度检验

如何进行梯度检查，来验证训练过程中是否出现bugs。

梯度检查首先要做的是分别将$W^{\left[ 1 \right]},b^{\left[ l \right]}, \dotsc ,W^{\left[ L \right]},b^{\left[ l \right]}$这些矩阵构造成一维向量，然后将这些一维向量组合起来构成一个更大的一维向量$\theta$。这样cost function $J\left( W^{\left[ 1 \right]},b^{\left[ l \right]}, \dotsc ,W^{\left[ L \right]},b^{\left[ l \right]} \right)$就可以表示成$J\left( \theta  \right)$。

然后将反向传播过程通过梯度下降算法得到的$dW^{\left[ 1 \right]},db^{\left[ l \right]}, \dotsc ,dW^{\left[ L \right]},db^{\left[ l \right]}$按照一样的顺序构造成一个一维向量$d\theta$。$d\theta$的维度与$\theta$一致。

接着利用$J\left( \theta  \right)$对每个$\theta _{i}$计算近似梯度，其值与反向传播算法得到的$d\theta _{i}$相比较，检查是否一致。例如，对于第i个元素，近似梯度为：

$d\theta _{approx}\left[ i \right]=\frac{J\left( \theta _{1},\theta _{2}, \dotsc ,\theta _{i}+\epsilon , \dotsc \right)-J\left( \theta _{1},\theta _{2}, \dotsc ,\theta _{i}-\epsilon , \dotsc \right)}{2\epsilon }$ 

计算完所有$\theta _{i}$的近似梯度后，**可以计算$d\theta _{approx}$与$d\theta$的欧氏（Euclidean）距离，然后用向量长度做归一化来比较二者的相似度**。公式如下：

$\frac{\left| \left| d\theta _{approx}-d\theta  \right| \right|_{2}}{\left| \left| d\theta _{approx} \right| \right|_{2}+\left| \left| d\theta  \right| \right|_{2}}$

其中，分母只是为了预防这些向量太小或太大，分母使得这个方程式变成比率。

**一般而言, 误差在$10^{-7}$以内的, 表明微分没问题，即反向梯度计算是正确的。误差在$10^{-5}$, 可能有点问题。 误差在$10^{-3}$的, 很有可能微分出错了**。

## 1.14 关于梯度检验实现的说明

- 不要在整个训练过程中都进行梯度检查，仅仅作为debug使用。

- 如果梯度检查出现错误，找到对应出错的梯度，检查其推导是否出现错误。
- 注意不要忽略正则化项，计算近似梯度的时候要包括进去。
- 梯度检查时关闭dropout，检查完毕后再打开dropout（梯度检查对 Dropout 无效，因为 Dropout 随机关停神经元，很难对成本函数进行定义）。
- 随机初始化时运行梯度检查，经过一些训练后再进行梯度检查（不常用）。

