## 优化算法

## 2.1 Mini-batch 梯度下降法

之前我们介绍的神经网络训练过程是对所有m个样本，称为batch，通过向量化计算方式，同时进行的。如果m很大，例如达到百万数量级，训练速度往往会很慢，因为每次迭代都要对所有样本进行进行求和运算和矩阵运算。我们将这种梯度下降算法称为**批量梯度下降（Batch Gradient Descent）**。

为了解决这一问题，我们可以把m个训练样本分成若干个子集，称为mini-batches，这样每个子集包含的数据量就小了，例如只有1000，然后每次在单一子集上进行神经网络训练，速度就会大大提高。这种梯度下降算法叫做**小批量梯度下降（Mini-batch Gradient Descent）**。

假设总的训练样本个数m=5000000，其维度为($n_{x}$,m)。将其分成5000个子集，每个mini-batch含有1000个样本。我们将每个mini-batch记为$X^{\left\{ t \right\}}$，其维度为($n_{x}$,1000)。相应的每个mini-batch的输出记为$Y^{\left\{ t \right\}}$，其维度为(1,1000)，且$t=1,2,\dotsc,5000$。

这里顺便总结一下我们遇到的神经网络中几类字母的上标含义：

$X^{\left( i \right)}$：第i个样本

$Z^{\left( l \right)}$：神经网络第l层网络的线性输出

$X^{\left\{ t \right\}}$,$Y^{\left\{ t \right\}}$：第t组mini-batch

**Mini-batches Gradient Descent的实现过程**是先将总的训练样本分成T个子集（mini-batches），然后对每个mini-batch进行神经网络训练，包括Forward Propagation，Compute Cost Function，Backward Propagation，循环至T个mini-batch都训练完毕。

```python
for  t=1,⋯,T  {
	Forward Propagation
	ComputeCostFunction
	BackwardPropagation
	W:=W−α⋅dW
	b:=b−α⋅db
}
```

经过T次循环之后，所有m个训练样本都进行了梯度下降计算。这个过程，我们称之为经历了一个epoch。对于Batch Gradient Descent而言，一个epoch只进行一次梯度下降算法；而Mini-Batches Gradient Descent，一个epoch会进行T次梯度下降算法。

值得一提的是，对于Mini-Batches Gradient Descent，可以进行多次epoch训练。而且，**每次epoch，最好是将总体训练数据重新打乱、重新分成T组mini-batches，这样有利于训练出最佳的神经网络模型**。

## 2.2 理解 Mini-batch 梯度下降法

Batch gradient descent和Mini-batch gradient descent的cost曲线如下图所示：

![梯度下降](http://img.blog.csdn.net/20171026113219156?)

对于一般的神经网络模型，使用Batch gradient descent，随着迭代次数增加，cost是不断减小的。然而，使用Mini-batch gradient descent，随着在不同的mini-batch上迭代训练，其cost不是单调下降，而是受类似noise的影响，出现振荡。但整体的趋势是下降的，最终也能得到较低的cost值。

**之所以出现细微振荡的原因是不同的mini-batch之间是有差异的**。例如可能第一个子集$\left( X^{\left\{ 1 \right\}},Y^{\left\{ 1 \right\}} \right)$是好的子集，而第二个子集$\left( X^{\left\{ 2 \right\}},Y^{\left\{ 2 \right\}} \right)$包含了一些噪声noise。出现细微振荡是正常的。

如何选择每个mini-batch的大小，即包含的样本个数呢？有两个极端：如果mini-batch size=m，即为批量梯度下降（Batch gradient descent），只包含一个子集为$\left( X^{\left\{ 1 \right\}},Y^{\left\{ 1 \right\}} \right)=\left( X,Y \right)$；如果mini-batch size=1，即为**随机梯度下降（Stachastic gradient descent）**，每个样本就是一个子集$\left( X^{\left\{ 1 \right\}},Y^{\left\{ 1 \right\}} \right)=\left( x^{\left( i \right)},y^{\left( i \right)} \right)$，共有m个子集。

BGD会比较平稳地接近全局最小值，但是因为使用了所有m个样本，每次前进的速度有些慢。SGD每次前进速度很快，但是路线曲折，有较大的振荡，最终会在最小值附近来回波动，难以真正达到最小值处。而且在数值处理上就不能使用向量化的方法来提高运算速度。

实际使用中，mini-batch size不能设置得太大（Batch gradient descent），也不能设置得太小（Stachastic gradient descent）。这样，相当于结合了Batch gradient descent和Stachastic gradient descent各自的优点，**既能使用向量化优化算法，又能叫快速地找到最小值**。

一般来说，如果总体样本数量m不太大时，例如m≤2000，建议直接使用Batch gradient descent。如果总体样本数量m很大时，建议将样本分成许多mini-batches。推荐常用的mini-batch size为64,128,256,512。这些都是2的幂。**之所以这样设置的原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度**。

## 2.3 指数加权平均

**指数加权平均 Exponentially weighted averages**，有时候也称指数加权移动平均，引入过去对现在的影响，而不单单考虑当前值，因此可以抚平短期波动，反映出长期的趋势。其一般形式为：

$V_{t}=\beta V_{t-1}+\left( 1-\beta  \right)\theta _{t}$

其中$\theta$是原始变量，V是对$\theta$进行了指数加权平均得到的变量，$\beta$是衰减率（一般取0.9），用于控制平均的量。$\beta$值决定了指数加权平均的天数，近似表示为：$\frac{1}{1-\beta }$

例如，当$\beta =0.9​$，则$\frac{1}{1-\beta }=10​$，表示将前10天进行指数加权平均。当$\beta =0.98​$，则$\frac{1}{1-\beta }=50​$，表示将前50天进行指数加权平均。**$\beta​$值越大，则指数加权平均的天数越多，平均后的趋势线就越平缓，但是同时也会向右平移**。

下图绿色曲线和黄色曲线分别表示了$\beta =0.98$和$\beta =0.5$时，指数加权平均的结果。

![指数加权平均](http://img.blog.csdn.net/20171027150509634?)

这里简单解释一下公式$\frac{1}{1-\beta }$是怎么来的。准确来说，指数加权平均算法跟之前所有天的数值都有关系，根据之前的推导公式就能看出。但是指数是衰减的，一般认为衰减到$\frac{1}{e}$就可以忽略不计了。因此，根据之前的推导公式，我们只要证明$\beta ^{\frac{1}{1-\beta }}=\frac{1}{e}$就好了。

令$\frac{1}{1-\beta }=N,N>0$，则$\beta =1-\frac{1}{N},\frac{1}{N}<1$。即证明转化为：$\left( 1-\frac{1}{N} \right)^{N}=\frac{1}{e}$

显然，当$N\gg0$时，上述等式是近似成立的。

## 2.4 理解指数加权平均

我们将指数加权平均公式的一般形式写下来：

$\begin{aligned} V_{t} & =\beta V_{t-1}+\left( 1-\beta  \right)\theta _{t} \\ & =\left( 1-\beta  \right)\theta _{t}+\left( 1-\beta  \right)\cdot \beta \cdot \theta _{t-1}+\left( 1-\beta  \right)\cdot \beta ^{2}\cdot \theta _{t-2}+\dotsb+\left( 1-\beta  \right)\cdot \beta ^{t-1}\cdot \theta _{1}+\beta ^{t}\cdot V_{0} \end{aligned}$

观察上面这个式子，$\theta _{t},\theta _{t-1},\theta _{t-2},\dotsc,\theta _{1}$是原始数据值，$\left( 1-\beta  \right),\left( 1-\beta  \right)\beta ,\left( 1-\beta  \right)\beta ^{2},\dotsc,\left( 1-\beta  \right)\beta ^{t-1}$是类似指数曲线，从右向左，呈指数下降的。$V_{t}$的值就是这两个子式的点乘，将原始数据值与衰减指数点乘，相当于做了指数衰减，离得越近，影响越大，离得越远，影响越小，衰减越厉害。

![理解指数加权平均](http://img.blog.csdn.net/20171027155944527?)

我们已经知道了指数加权平均的递推公式。实际应用中，为了减少内存的使用，我们可以使用这样的语句来实现指数加权平均算法：

```python
Vθ=0
Repeat {
	Get next θt
	Vθ:=βVθ+(1−β)θt
}
```

## 2.5 指数加权平均的偏差修正

上文中提到当$\beta =0.98$时，指数加权平均结果如下图绿色曲线所示。但是实际上，真实曲线如紫色曲线所示。

![指数加权平均的修正](http://img.blog.csdn.net/20171028095447301?)

我们注意到，紫色曲线与绿色曲线的区别是，紫色曲线开始的时候相对较低一些。这是因为开始时我们设置$V_{0}=0$，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常。

由于$V_{0}=0$，指数加权平均刚开始计算时，$V_{t}$与$\theta _{t}$偏差很大。**偏移校正（bias correction）**用于解决该问题，即在每次计算完$V_{t}$后，对$V_{t}$进行如下处理：$\frac{V_{t}}{1-\beta ^{t}}$。

在刚开始的时候，t比较小，$\left( 1-\beta ^{t} \right)<1$，这样就能将$V_{t}$修正得更大一些。随着t增大，$\left( 1-\beta ^{t} \right) \approx1$ ，$V_{t}$基本不变，这样就实现了简单的偏移校正。

值得一提的是，机器学习中，偏移校正并不是必须的。因为，在迭代一次次数后（t较大），$V_{t}$受初始值影响微乎其微，紫色曲线与绿色曲线基本重合。所以，一般可以忽略初始迭代过程，等到一定迭代之后再取值，这样就不需要进行偏移校正了。

## 2.6 动量梯度下降法

**动量梯度下降法（Gradient descent with momentum）**，就是将指数加权平均引入梯度下降算法，用参数更新量的指数加权平均结果代替参数更新量来更新参数。做法是在每次训练时，对梯度进行指数加权平均处理，然后用得到的梯度值更新权重W和常数项b，其速度要比传统的梯度下降算法快很多。

![动量梯度下降](http://img.blog.csdn.net/20171028142838569?)

权重W和常数项b的指数加权平均表达式如下：

$V_{dW}=\beta \cdot V_{dW}+\left( 1-\beta  \right)\cdot dW$

$V_{db}=\beta \cdot V_{db}+\left( 1-\beta  \right)\cdot db$

$W:=W-\alpha V_{dW},b:=b-\alpha V_{db}$

从动量的角度来看，以权重W为例，$V_{dW}$可以成速度V，$dW$可以看成是加速度a。指数加权平均实际上是计算当前的速度，当前速度由之前的速度和现在的加速度共同影响。而$\beta <1$，又能限制速度$V_{dW}$过大。**也就是说，当前的速度是渐变的，而不是瞬变的，是动量的过程**。这保证了梯度下降的平稳性和准确性，减少振荡，较快地达到最小值处。

动量梯度下降算法的过程如下：

On iteration t:

​	Compute dW，db on the current mini−batch

​	$V_{dW}=\beta \cdot V_{dW}+\left( 1-\beta  \right)\cdot dW$

​	$V_{db}=\beta \cdot V_{db}+\left( 1-\beta  \right)\cdot db$

​	$W:=W-\alpha V_{dW},b:=b-\alpha V_{db}$
初始时，令$V_{dW}=0$，$V_{db}=0$。一般设置$\beta =0.9$，即指数加权平均前10天的数据，实际应用效果较好。

另外，关于偏移校正，可以不使用。因为经过10次迭代后，随着滑动平均的过程，偏移情况会逐渐消失。

在其它文献资料中，动量梯度下降还有另外一种写法：

$V_{dW}=\beta \cdot V_{dW}+dW$

$V_{db}=\beta \cdot V_{db}+db$

即消去了$dW$和$db$前的系数$\left( 1-\beta  \right)$。这样简化了表达式，但是学习因子$\alpha $相当于变成了$\frac{\alpha }{1-\beta }$，表示$\alpha $也受$\beta $的影响。从效果上来说，这种写法也是可以的，但是不够直观，且调参涉及到$\alpha $，不够方便。所以，实际应用中，推荐第一种动量梯度下降的表达式。

## 2.7 RMSprop

RMSprop是另外一种优化梯度下降速度的算法。每次迭代训练过程中，其权重W和常数项b的更新表达式为：

$\mbox{S}_{w}=\beta \mbox{S}_{dW}+\left( 1-\beta  \right)d^{2}W$

$\mbox{S}_{b}=\beta \mbox{S}_{db}+\left( 1-\beta  \right)d^{2}b$

$W:=W-\alpha \frac{dW}{\sqrt{\mbox{S}_{w}}},b:=b-\alpha \frac{db}{\sqrt{\mbox{S}_{b}}}$

RMSprop 能加速梯度下降收敛，解释如下: 对 dW 求平方，首先放大了参数 W 的增大或减小量，然后求指数加权平均，累加了增大或减小的效果，结果$\mbox{S}_{w}$就是一个极大或极小的值。假设$\mbox{S}_{w}$极大，$\frac{dW}{\sqrt{\mbox{S}_{w}}}$就变小; $\mbox{S}_{w}$极小，$\frac{dW}{\sqrt{\mbox{S}_{w}}}$就变大， 从而减轻了梯度下降的震荡，保证梯度下降的正轨。**RMS 由此得名，对均方$S_{W}$求根**。

RMSprop 的一个好处是，由于使用$\frac{dW}{\sqrt{\mbox{S}_{w}}}$减轻了震荡，**就可以使用一个较大的学习率$\alpha$，加速学习**。

**为了避免RMSprop算法中分母为零**，通常可以在分母增加一个极小的常数$\epsilon $：

$W:=W-\alpha \frac{dW}{\sqrt{\mbox{S}_{w}+\epsilon} },b:=b-\alpha \frac{db}{\sqrt{\mbox{S}_{b}+\epsilon} }$

其中，$\epsilon =10^{-8}​$，或者其它较小值。

## 2.8 Adam 优化算法

Adam（Adaptive Moment Estimation）算法结合了动量梯度下降算法和RMSprop算法。其算法流程为：

$V_{dW}=0,\ S_{dW},\ V_{db}=0,\ S_{db}=0$

On iteration t:

​    Cimpute dW，db

$\ \ \ \ S_{dW}=\beta_2S_{dW}+(1-\beta_2)dW^2,\ S_{db}=\beta_2S_{db}+(1-\beta_2)db^2$

$\ \ \ \ V_{dW}^{corrected}=\frac{V_{dW}}{1-\beta_1^t},\ V_{db}^{corrected}=\frac{V_{db}}{1-\beta_1^t}$

$\ \ \ \ S_{dW}^{corrected}=\frac{S_{dW}}{1-\beta_2^t},\ S_{db}^{corrected}=\frac{S_{db}}{1-\beta_2^t}$

$\ \ \ \ W:=W-\alpha\frac{V_{dW}^{corrected}}{\sqrt{S_{dW}^{corrected}}+\varepsilon},\ b:=b-\alpha\frac{V_{db}^{corrected}}{\sqrt{S_{db}^{corrected}}+\varepsilon}$

Adam算法包含了几个超参数，分别是：$\alpha,\beta_1,\beta_2,\varepsilon$。其中，$\beta_1$通常设置为0.9，$\beta_2$通常设置为0.999，$\varepsilon$通常设置为$10^{-8}$。一般只需要对$\beta_1$和$\beta_2$进行调试。

## 2.9 学习率衰减

**学习率衰减（learning rate decay）**就是随着迭代次数增加，学习因子$\alpha$逐渐减小。

减小学习因子α也能有效提高神经网络训练速度。原因在于，MBGD/SGD 并不能获得全局最优解，即使选择了一个能收敛的学习率，当成本曲折地下降到全局最优解附近时，由于学习率始终不变，成本可能会以一个较大的偏差幅度在全局最优解附近震荡。

下图中，蓝色折线表示使用恒定的学习因子α，由于每次训练α相同，步进长度不变，在接近最优值处的振荡也大，在最优值附近较大范围内振荡，与最优值距离就比较远。绿色折线表示使用不断减小的α，随着训练次数增加，α逐渐减小，步进长度减小，使得能够在最优值处较小范围内微弱振荡，不断逼近最优值。相比较恒定的α来说，学习率衰减更接近最优值。

![学习率衰减](http://img.blog.csdn.net/20171028212226321?)

常用的学习率衰减公式：

- $\alpha =\frac{1}{1\; +\; decay\_rate\; \times \; epoch}\alpha _{0}$ 

其中，deacy_rate是参数（可调），epoch是训练完所有样本的次数。随着epoch增加，$\alpha$会不断变小。 

- $\alpha =0.95^{epoch}\cdot \alpha _{0}$

指数衰减，底数可以自由地选择小于 1 的数。

- $\alpha =\frac{k}{\sqrt{epoch}}\cdot \alpha _{0}\; or\; \frac{k}{\sqrt{t}}\cdot \alpha _{0}$

其中，k为可调参数，t为mini-bach number。

除此之外，还可以设置$\alpha$为关于t的离散值，随着t增加，$\alpha$呈阶梯式减小。当然，也可以根据训练情况灵活调整当前的α值，但会比较耗时间。

## 2.10 局部最优的问题

在使用梯度下降算法不断减小cost function时，可能会得到局部最优解（local optima）而不是全局最优解（global optima）。之前我们对局部最优解的理解是形如碗状的凹槽，如下图左边所示。但是在神经网络中，局部最优解的概念发生了变化。准确地来说，大部分梯度为零的“最优点”并不是这些凹槽处，而是形如右边所示的马鞍状，称为鞍点（saddle point）。也就是说，梯度为零并不能保证都是convex（极小值），也有可能是concave（极大值）。**特别是在神经网络中参数很多的情况下，所有参数梯度为零的点很可能都是右边所示的马鞍状的鞍点，而不是左边那样的局部最优解**。

![局部最优](http://img.blog.csdn.net/20171028232352807?)

类似马鞍状的台地（plateaus）会降低神经网络学习速度。台地是梯度接近于零的平缓区域，如下图所示。在台地上梯度很小，前进缓慢，到达鞍点需要很长时间。到达鞍点后，由于随机扰动，梯度一般能够沿着图中绿色箭头，离开鞍点，继续前进，只是在台地上花费了太多时间。

关于局部最优解，有两点总结：

- **只要选择合理的强大的神经网络，一般不太可能陷入局部最优解**
- **台地可能会使梯度下降变慢，降低学习速度**

值得一提的是，上文介绍的动量梯度下降，RMSprop，Adam算法都能有效解决台地下降过慢的问题，大大提高神经网络的学习速度。